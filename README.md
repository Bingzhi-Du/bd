# Big data engineering(BDE) notebook
## Tools of BDE: Introduction and Installation
### System Requirements
- Windows 11
- AMD Ryzen 6800
### Using PySpark on Google Colab
- [Instructions on setting up PySpark on Google Colab](<link-to-colab-setup>)
### Using PySpark on Windows
- [Guide for PySpark installation on Windows](<link-to-windows-setup>)
### Prerequisites for PySpark
Before installing PySpark, ensure that the following dependencies are installed:
- Java (Spark runs on Java 8/11/17)
- Scala (Version 2.12 or 2.13)
- Spark
> **Note**: PySpark requires Python version 3.8 or later, and for R users, R version 3.5 or later is needed.
### Additional Resources
- [Link to more detailed guides or resources](<resource-link>)

  # tools of BDE introduction installation
  WIN 11 AMD6800
  Pyspark on google Colab
  Pyspark on win
  scala/java/spark are needed before use the install Pyspark lib
  Spark runs on Java 8/11/17, Scala 2.12/2.13, Python 3.8+, and R 3.5+ (3.5version)
      
https://spark.apache.org/docs/latest/index.html
      
      # version control between scala&spark(generally:spark 3.+ match scala 2.12.X/2.13.X)
      # java 17 LTS is recommened (java 21 LTS is NOT suit for spark 3.5 or 3.5-)
      # scala & spark matched version check 
      
https://mvnrepository.com/artifact/org.apache.spark/spark-core

      # Creat a python environment for pyspark
      conda create -n pyspark_env python=3.9
      # activate new env (or conda activate pyspark_env)
      activate pyspark_env
    # linux server set of Pyspark
      # installations:
      # 
      # Virtual server for Pyspark
      # linux sys version
      # cmd code
  # demo of BDE flow on Pyspark
    # basic function of Pyspark-read
    # basic function/definition of RDD
    # functions list
  # BDE in defferent area
    # Finance
