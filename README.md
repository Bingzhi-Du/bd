# Big data engineering(BDE) notebook
  # tools of BDE introduction installation
    # WIN 11 AMD6800
    # Pyspark on google Colab
    # Pyspark on win
      # scala/java/spark are needed before use the install Pyspark lib
      # Spark runs on Java 8/11/17, Scala 2.12/2.13, Python 3.8+, and R 3.5+ (3.5version)
      
https://spark.apache.org/docs/latest/index.html
      
      # version control between scala&spark(generally:spark 3.+ match scala 2.12.X/2.13.X)
      # java 17 LTS is recommened (java 21 LTS is NOT suit for spark 3.5 or 3.5-)
      # scala & spark matched version check 
      
https://mvnrepository.com/artifact/org.apache.spark/spark-core

      # Creat a python environment for pyspark
conda create -n pyspark_env python=3.9
      # activate new env 
activate pyspark_env
(or conda activate pyspark_env)

    # linux server set of Pyspark
      # installations:
      # 
      # Virtual server for Pyspark
      # linux sys version
      # cmd code
  # demo of BDE flow on Pyspark
    # basic function of Pyspark-read
    # basic function/definition of RDD
    # functions list
  # BDE in defferent area
    # Finance
